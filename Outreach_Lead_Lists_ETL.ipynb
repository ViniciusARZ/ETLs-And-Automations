{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D67IY_u6lc0z"
      },
      "source": [
        "#Packages & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVuZiH-Mok7L"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade gspread\n",
        "!pip install -q pandas\n",
        "!pip install -q -U -q PyDrive\n",
        "!pip install -q datetime\n",
        "!pip install -q pendulum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0UiZALOo2E-"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "import re\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "import datetime\n",
        "import pendulum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAmnujmiNT6s"
      },
      "source": [
        "#Getting Prospection Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKN1M6SrRCzo"
      },
      "source": [
        "Check the prospects tables for N/As, so:\n",
        "1. Open them one by one and see if they load without problems: [Prospects 1], [Prospects 2], [Prospects 3]\n",
        "2. If all of them are alright, run the following cells\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDgDvUvvfG8d"
      },
      "outputs": [],
      "source": [
        "# Prospects Table\n",
        "p1 = gc.open_by_key('KEY')\n",
        "p1_data = p1.worksheet('Prospects')\n",
        "p1rows = p1_data.get_all_values()\n",
        "df_p1 = pd.DataFrame.from_records(p1rows[1:],columns=p1rows[0])\n",
        "# Prospects 2 Table\n",
        "p2 = gc.open_by_key('KEY')\n",
        "p2_data = p2.worksheet('Sheet1')\n",
        "p2rows = p2_data.get_all_values()\n",
        "df_p2 = pd.DataFrame.from_records(p2rows[1:],columns=p2rows[0])\n",
        "p3 = gc.open_by_key('KEY')\n",
        "# Prospects 3 Table\n",
        "p3_data = p3.worksheet('All')\n",
        "p3rows = p3_data.get_all_values()\n",
        "df_p3 = pd.DataFrame.from_records(p3rows[1:],columns=p3rows[0])\n",
        "\n",
        "# Joining them\n",
        "prospects_df = pd.concat([df_p1,df_p2,df_p3],axis=0)\n",
        "#Adding domain column\n",
        "prospects_df['domain'] = prospects_df['Email'].str.split('@').str[1] # adding Domain column\n",
        "#Adding Week Column\n",
        "prospects_df['Date'] = pd.to_datetime(prospects_df['Date'])\n",
        "prospects_df['WeekNum'] = prospects_df['Date'].dt.strftime('%Y-%b-w%U')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prospects_df[prospects_df['Company Name']==\"MAPFRE Salud ARS\"]"
      ],
      "metadata": {
        "id": "z7n3Rpa4dpP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tG5m-TKIZXq"
      },
      "source": [
        "# Outreach Weekly Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3Pczfv3cdNP"
      },
      "source": [
        "## Selecting Outreach Weekly Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYA814y5mzDo"
      },
      "source": [
        "Filtering previous week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtYxzo6mG63X"
      },
      "outputs": [],
      "source": [
        "prosp_out_df = prospects_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7awUZ5RTgtGl",
        "outputId": "d58cd6e5-a291-4d34-f17c-12b836fbcaf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2022-Jan-w04'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "mydate = datetime.date.today()\n",
        "current_week = mydate.strftime('%Y-%b-w%U')\n",
        "current_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sv_oJ6atbdZX",
        "outputId": "553eac24-27cd-42c8-cb19-66e868bb49cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2022-Jan-w03'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "today = datetime.date.today() #used to get the today datetime\n",
        "weekday = today.weekday() #get the weekday\n",
        "start_delta = datetime.timedelta(days=weekday, weeks=1) #delta of the previous week based on the day\n",
        "start_of_week = today - start_delta #substracting the delta to get a a date respective to the previous week\n",
        "start_of_week\n",
        "outreach_week = start_of_week.strftime('%Y-%b-w%U') #transforming to be in the same format as the dataset\n",
        "outreach_week"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date, timedelta   \n",
        "last_friday = today - timedelta(days=today.weekday()) + timedelta(days=4, weeks=-1)\n",
        "last_monday = today - timedelta(days=today.weekday()) + timedelta(days=7, weeks=-2)\n",
        "print(\"Dates: \", last_monday, \"to\", last_friday)\n",
        "#outreach_week['Date'] = pd.to_datetime(outreach_week['Date'])\n",
        "#print(weekly_outreach_raw[(weekly_outreach_raw['Date'] >= pd.Timestamp(last_monday)) & (weekly_outreach_raw['Date'] <= pd.Timestamp(last_friday))])"
      ],
      "metadata": {
        "id": "4m7JfpFm_h-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd71175a-973a-4d11-cabe-e00122f7b827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dates:  2022-01-17 to 2022-01-21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DshBEIIfl9u",
        "outputId": "e0ed6928-4cf0-47fc-c874-e16e2c19ca86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2274, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Filtered but not treated\n",
        "prosp_out_df['Date'] = pd.to_datetime(prosp_out_df['Date'])\n",
        "weekly_outreach_raw = prosp_out_df[(prosp_out_df['Date'] >= pd.Timestamp(last_monday)) & (prosp_out_df['Date'] <= pd.Timestamp(last_friday))]\n",
        "weekly_outreach_raw.sort_values('Date').shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQKiXbVMkhRB"
      },
      "source": [
        "## Clean-up & Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elXysi-1kYFn"
      },
      "source": [
        "### Applying Head Industries & Translating Industries Names ver.2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFdwf40F3iqj"
      },
      "source": [
        "Head and Sub Industries Dictionary from [Industries File]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaiIVR5bXVmQ"
      },
      "outputs": [],
      "source": [
        "ind_accesss = gc.open_by_key('KEY')\n",
        "ind_data = ind_accesss.worksheet('Industries 2021 (old)')\n",
        "indsrows = ind_data.get_all_values()\n",
        "df_industries = pd.DataFrame.from_records(indsrows[1:],columns=indsrows[0])\n",
        "ind_dict = dict(zip(df_industries['Industry'],df_industries['Head Industry']))\n",
        "#Adding Head Industry column to prospection tables\n",
        "weekly_outreach_raw['Head Industry'] = weekly_outreach_raw[\"Industry\"].map(ind_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1tXdxqWf7gS"
      },
      "source": [
        "Applying Industries Translations using [another table] as Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgikqSuuf2uy"
      },
      "outputs": [],
      "source": [
        "ind_trans_accesss = gc.open_by_key('KEY')\n",
        "ind_trans_data = ind_trans_accesss.worksheet('Sheet1')\n",
        "indstransrows = ind_trans_data.get_all_values()\n",
        "df_industries_trans = pd.DataFrame.from_records(indstransrows[1:],columns=indstransrows[0])\n",
        "ind_dict_pt = dict(zip(df_industries_trans['Industry (EN)'],df_industries_trans['Industry (PT)'])) # dictionary for Brasil\n",
        "ind_dict_es = dict(zip(df_industries_trans['Industry (EN)'],df_industries_trans['Industry (ES)'])) # dictionary for LATAM & MX\n",
        "\n",
        "def ind_trans(weekly_outreach_raw):\n",
        "  if(weekly_outreach_raw['Country'] == 'Brasil' or weekly_outreach_raw['Country'] == 'Brazil'):\n",
        "    return weekly_outreach_raw[['Industry']].map(ind_dict_pt)\n",
        "  elif (weekly_outreach_raw['Country'] not in ['Brasil','Brazil']):\n",
        "    return weekly_outreach_raw[['Industry']].map(ind_dict_es)\n",
        "\n",
        "weekly_outreach_fil = weekly_outreach_raw.assign(Industry_T=weekly_outreach_raw.apply(ind_trans,axis=1))\n",
        "weekly_outreach_fil.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Head Industries & Translating Industry Names ver.2022"
      ],
      "metadata": {
        "id": "rWHMT4XD9t6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind_accesss = gc.open_by_key('KEY')\n",
        "ind_data = ind_accesss.worksheet('(IGNORE) Ind2022')\n",
        "indsrows = ind_data.get_all_values()\n",
        "df_industries = pd.DataFrame.from_records(indsrows[1:],columns=indsrows[0])\n",
        "ind_dict = dict(zip(df_industries['Industry'],df_industries['Head Industry']))\n",
        "#Adding Head Industry column to prospection tables\n",
        "weekly_outreach_raw['Head Industry'] = weekly_outreach_raw[\"Industry\"].map(ind_dict)"
      ],
      "metadata": {
        "id": "COl1wwa493F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_dict_pt = dict(zip(df_industries['Industry'],df_industries['Industry PT'])) # dictionary for Brasil\n",
        "ind_dict_es = dict(zip(df_industries['Industry'],df_industries['Industry SP'])) # dictionary for LATAM & MX\n",
        "\n",
        "def ind_trans(weekly_outreach_raw):\n",
        "  if(weekly_outreach_raw['Country'] == 'Brasil' or weekly_outreach_raw['Country'] == 'Brazil'):\n",
        "    return weekly_outreach_raw[['Industry']].map(ind_dict_pt)\n",
        "  elif (weekly_outreach_raw['Country'] not in ['Brasil','Brazil']):\n",
        "    return weekly_outreach_raw[['Industry']].map(ind_dict_es)\n",
        "\n",
        "weekly_outreach_fil = weekly_outreach_raw.assign(Industry_T=weekly_outreach_raw.apply(ind_trans,axis=1))\n",
        "weekly_outreach_fil.head(3)"
      ],
      "metadata": {
        "id": "fEJw3dNb-TsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KzKB8EOdvXx"
      },
      "source": [
        "### Checking for Prospection Periods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MSC0nugjaVe"
      },
      "source": [
        "####Checking Last Prospection Date for the Domain crossed with Country and removing <90 days ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnf0DA0QtStE"
      },
      "source": [
        "Using loc with subtraction of duplicated combinations of domain and country to keep only a dataset with \"lasts\" to pass on the filter later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_bxzgHSmp0G"
      },
      "outputs": [],
      "source": [
        "ptest = prosp_out_df[prosp_out_df['WeekNum']!=outreach_week].copy()\n",
        "m1 = ~ptest.duplicated(['domain','Country'], keep='last')\n",
        "m2 = ptest.duplicated(['domain','Country'], keep= False)\n",
        "m = m1 & m2\n",
        "ptest.loc[m, 'Last'] = 'Last'\n",
        "lastdomain_df = ptest[ptest['Last']=='Last']\n",
        "lastdomain_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtCSv2Xzj-2h"
      },
      "source": [
        "Shape of Outreach File after matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxFOsggRgKch",
        "outputId": "69fd6cb9-fd8b-43b8-aea3-daa46f3f0edc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2274, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test_merge = weekly_outreach_fil.merge(lastdomain_df[['Date','domain','Country','LGA','Company Name']], on =['domain','Country'],how='left')#.drop_duplicates(['Email'])\n",
        "test_merge.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeVVILJVkDIO"
      },
      "source": [
        "Finding < 90 Days companies crossing Country and Domain attributes and showing the shape after dropping rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve2agGySjvyR",
        "outputId": "b90ba34a-9538-49ee-efd8-96c96c09f62a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2274, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_merge['Date_x'] = pd.to_datetime(test_merge['Date_x'])\n",
        "test_merge['Date_y'] = pd.to_datetime(test_merge['Date_y'])\n",
        "test_merge['LastProspDate'] = (test_merge['Date_x'] - test_merge['Date_y']).dt.days\n",
        "#test_merge[(test_merge['LastProspDate'] < 90) & (test_merge['LastProspDate'] != 0) & (test_merge['LastProspDate']!= \"NaN\")]\n",
        "#test_merge = test_merge.drop(test_merge[(test_merge['LastProspDate'] < 90) & (test_merge['LastProspDate'] != 0) & (test_merge['LastProspDate']!= \"NaN\")].index)\n",
        "test_merge.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vff-Dal5k9KJ"
      },
      "source": [
        "Difference in x is contacts with less than 90 days that were removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY5rm-D9lEfS"
      },
      "source": [
        "####Checking Last Prospection Date for emails and removing <220 days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwsWt6z5vo3P"
      },
      "source": [
        "Same logic, but for e-mails, using loc with subtraction of duplicated combinations of email to keep only a dataset with \"lasts\" to pass on the filter later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtyzLLMwvo3Q",
        "outputId": "645f0da3-2489-4088-9cd2-9262c30ece0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26218, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "ptest_email = prosp_out_df[prosp_out_df['WeekNum']!=outreach_week].copy()\n",
        "m1_email = ~ptest_email.duplicated(['Email'], keep='last')\n",
        "m2_email = ptest_email.duplicated(['Email'], keep= False)\n",
        "m_email = m1_email & m2_email\n",
        "ptest_email.loc[m_email, 'Last'] = 'Last'\n",
        "lastemail_df = ptest_email[ptest_email['Last']=='Last']\n",
        "lastemail_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q32R2FridzlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4d53f4-d398-46c6-b6cc-d017942a0148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2274, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "test_merge2 = test_merge.merge(lastemail_df[['Date','Email','Country','Name']], on =['Email','Country'],how='left')#.drop_duplicates(['Email'])\n",
        "test_merge2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L95zGxbwlmY5",
        "outputId": "f30f26b4-f601-485a-eaab-bc523d3ebc22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2274, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "test_merge2['LastProspEmailDate'] = (test_merge2['Date_x'] - test_merge2['Date']).dt.days\n",
        "#test_merge2[(test_merge2['LastProspEmailDate'] < 220) & (test_merge2['LastProspEmailDate'] != 0) & (test_merge2['LastProspEmailDate']!= \"NaN\")]\n",
        "#test_merge2 = test_merge2.drop(test_merge2[(test_merge2['LastProspEmailDate'] < 220) & (test_merge2['LastProspEmailDate'] != 0) & (test_merge2['LastProspEmailDate']!= \"NaN\")].index)\n",
        "test_merge2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking last Contact on Hubspot"
      ],
      "metadata": {
        "id": "MomjapP7sR9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing Hubspot's Contacts Report"
      ],
      "metadata": {
        "id": "id_nRgfqseX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hb_cont_download = drive.CreateFile({'id':'KEY'})\n",
        "hb_cont_download.GetContentFile('ContactReport.xlsx')\n",
        "hbcontacts_df = pd.read_excel('ContactReport.xlsx')\n",
        "hbcontacts_df.columns"
      ],
      "metadata": {
        "id": "WqfNfhHisXX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8XnLdVVuY9k"
      },
      "outputs": [],
      "source": [
        "hb_merge1 = test_merge2.merge(hbcontacts_df[['Last Activity Date','Email']], on =['Email'],how='left')#.drop_duplicates(['Email'])\n",
        "hb_merge1['LastHubSpotDate'] = (hb_merge1['Date_x'] - hb_merge1['Last Activity Date']).dt.days\n",
        "hb_merge1['LastHubSpotDate']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking last contact on Mailshake"
      ],
      "metadata": {
        "id": "9nOW_MzKwydq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msreport_downl = drive.CreateFile({'id':'KEY'})\n",
        "msreport_downl.GetContentFile('MailshakeReport.csv')\n",
        "mailshake_df = pd.read_csv('MailshakeReport.csv',delimiter=\";\")\n",
        "mailshake_df.columns"
      ],
      "metadata": {
        "id": "CscY4m67wxwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1_ms = ~mailshake_df.duplicated(['Email'], keep='last')\n",
        "m2_ms = mailshake_df.duplicated(['Email'], keep= False)\n",
        "m_ms = m1_ms & m2_ms\n",
        "mailshake_df.loc[m_ms, 'Last'] = 'Last'\n",
        "lastms_df = mailshake_df[mailshake_df['Last']=='Last']\n",
        "lastms_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSw3XMrlxFHD",
        "outputId": "f8fafaff-fadf-4877-d1e4-2f692168622d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129410, 149)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86dddc5a-ffcf-4969-cf8f-c21a8c2372e7",
        "id": "c4mEeEw9wxwU"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2274, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "ms_merge1 = hb_merge1.merge(lastms_df[['Sent date','Email']], on =['Email'],how='left')#.drop_duplicates(['Email'])\n",
        "ms_merge1['Sent date'] = pd.to_datetime(ms_merge1['Sent date'])\n",
        "ms_merge1['LastMailShakeDate'] = (ms_merge1['Date_x'] - ms_merge1['Sent date']).dt.days\n",
        "ms_merge1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Denining final columns after check"
      ],
      "metadata": {
        "id": "WJD0PJY2uNEi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr4k1mZ3Z7Fx"
      },
      "source": [
        "Re-defining weekly_outreach_fil as the output to work on next functions and dropping formulated columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k7gJTbTZ6i_"
      },
      "outputs": [],
      "source": [
        "weekly_outreach_fil = ms_merge1[['Date_x', 'Company Name_x', 'ID', 'S-ID', 'LGA_x', 'Country', 'City',\n",
        "       'Score Corp', 'Course 1', 'Course 2', 'Web page', 'First Name',\n",
        "       'Last Name', 'Contact Name', 'Score', 'Title', 'Email',\n",
        "       'LinkedIn Profile', 'Phone', 'Industry','Industry_T', 'Company ID', 'website',\n",
        "       'Name_x', 'NeverBounce', 'domain', 'WeekNum', 'Head Industry',\n",
        "       'LastProspDate','LastProspEmailDate','LastHubSpotDate','LastMailShakeDate']].rename(columns={'Date_x':'Date','Company Name_x':'Company Name','LGA_x':'LGA','Name_x':'Name','Industry_T':'Sector'})\n",
        "weekly_outreach_fil.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rSmljVbEYWy"
      },
      "source": [
        "### Checking for Email Duplicates and Dropping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCUXaiTBLxDz"
      },
      "source": [
        "Function to check on Duplicates, show them and remove them if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfTpKGVPHLm6"
      },
      "outputs": [],
      "source": [
        "check_email_dup = weekly_outreach_fil[['Email','Company Name','LGA']].groupby(['LGA','Email']).count()\n",
        "check_email_dup['Company Name'] = pd.to_numeric(check_email_dup['Company Name'])\n",
        "def checkdup(check_email_dup):\n",
        "  if [i for i in check_email_dup['Company Name'] if i > 1]:\n",
        "    return print(\" ## HAS DUPLICATES THAT WILL BE ELIMINATED ## \", check_email_dup[check_email_dup['Company Name']>1])\n",
        "  else:\n",
        "    return print(\"No Duplicates\")\n",
        "checkdup(check_email_dup)\n",
        "weekly_outreach = weekly_outreach_fil.drop_duplicates('Email') #outreach file without duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwoAofp_FKEH"
      },
      "source": [
        "### Applying Cluster Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNk1ZKQMod6D"
      },
      "source": [
        "Dropping Industry & Head Industry columns as keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIrVLdQAK36g"
      },
      "outputs": [],
      "source": [
        "df_industries_bdr = df_industries.drop(['Industry','Head Industry'],axis=1)\n",
        "df_industries_bdr.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x77pKYm9XBM_"
      },
      "source": [
        "Dictonaries based on the [Industries Table] to map Clusters according to Head Industries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Z4ywbfN4c_"
      },
      "outputs": [],
      "source": [
        "c_mx_dict = dict(zip(df_industries_bdr['HEAD INDUSTRIES'],df_industries['MX CLUSTER']))\n",
        "c_br_dict = dict(zip(df_industries_bdr['HEAD INDUSTRIES'],df_industries['BRASIL CLUSTER']))\n",
        "c_latam_dict = dict(zip(df_industries_bdr['HEAD INDUSTRIES'],df_industries['LATAM CLUSTER']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G26A6HrrWwDy"
      },
      "source": [
        "Function that uses the previous dictionaries to apply .maps based on the Head Industry from prospection and creates a column with results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-mErCQ_Q6ew"
      },
      "outputs": [],
      "source": [
        "def cluster_names(weekly_outreach):\n",
        "  if(weekly_outreach['Country'] == 'Brasil' or weekly_outreach['Country'] == 'Brazil'):\n",
        "    return weekly_outreach[['Head Industry']].map(c_br_dict)\n",
        "  elif (weekly_outreach['Country'] == 'Mexico' or weekly_outreach['Country'] == 'México'):\n",
        "    return weekly_outreach[['Head Industry']].map(c_mx_dict)\n",
        "  elif (weekly_outreach['Country'] not in ['Brasil','Brazil','Mexico','México']):\n",
        "    return weekly_outreach[['Head Industry']].map(c_latam_dict)\n",
        "\n",
        "df_outreach_cluster = weekly_outreach.assign(Cluster=weekly_outreach.apply(cluster_names,axis=1))\n",
        "df_outreach_cluster.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4q0YCjWvcSx"
      },
      "source": [
        "Now Dictionaries based on the same table but returning BDRs' Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFf83rQnvbn6"
      },
      "outputs": [],
      "source": [
        "c_mx_dict_bdr = dict(zip(df_industries_bdr['HEAD INDUSTRIES'],df_industries['MX BDR']))\n",
        "c_br_dict_bdr = dict(zip(df_industries_bdr['HEAD INDUSTRIES'],df_industries['BRASIL BDR']))\n",
        "c_latam_dict_bdr = dict(zip(df_industries_bdr['HEAD INDUSTRIES'],df_industries['LATAM BDR']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mslF04JovaPK"
      },
      "outputs": [],
      "source": [
        "def bdrs_names(df_outreach_cluster):\n",
        "  if(df_outreach_cluster['Country'] == 'Brasil' or df_outreach_cluster['Country'] == 'Brazil'):\n",
        "    return df_outreach_cluster[['Head Industry']].map(c_br_dict_bdr)\n",
        "  elif (df_outreach_cluster['Country'] == 'Mexico' or df_outreach_cluster['Country'] == 'México'):\n",
        "    return df_outreach_cluster[['Head Industry']].map(c_mx_dict_bdr)\n",
        "  elif (df_outreach_cluster['Country'] not in ['Brasil','Brazil','Mexico','México']):\n",
        "    return df_outreach_cluster[['Head Industry']].map(c_latam_dict_bdr)\n",
        "\n",
        "df_outreach = df_outreach_cluster.assign(BDR=df_outreach_cluster.apply(bdrs_names,axis=1))\n",
        "df_outreach.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Cluster Structure ver.2022"
      ],
      "metadata": {
        "id": "DjMjJJO3_VKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Segmentation Column"
      ],
      "metadata": {
        "id": "71j6lAGkAuTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seg_dict = dict(zip(df_industries['Industry'],df_industries['Segmentation']))\n",
        "weekly_outreach['SegmAux'] = weekly_outreach[['Industry']].map(seg_dict)"
      ],
      "metadata": {
        "id": "8x-1yPU1_rnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Cluster Column"
      ],
      "metadata": {
        "id": "hE-vQ4wpAmFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_mx_dict = dict(zip(df_industries['Industry'],df_industries['MX CLUSTER']))\n",
        "c_br_dict = dict(zip(df_industries['Industry'],df_industries['BR CLUSTER']))\n",
        "c_latam_dict = dict(zip(df_industries['Industry'],df_industries['LATAM CLUSTER']))\n",
        "\n",
        "def cluster_names(weekly_outreach):\n",
        "  if(weekly_outreach['Country'] == 'Brasil' or weekly_outreach['Country'] == 'Brazil'):\n",
        "    return weekly_outreach[['Industry']].map(c_br_dict)\n",
        "  elif (weekly_outreach['Country'] == 'Mexico' or weekly_outreach['Country'] == 'México'):\n",
        "    return weekly_outreach[['Industry']].map(c_mx_dict)\n",
        "  elif (weekly_outreach['Country'] not in ['Brasil','Brazil','Mexico','México']):\n",
        "    return weekly_outreach[['Industry']].map(c_latam_dict)\n",
        "\n",
        "df_outreach_cluster = weekly_outreach.assign(Cluster=weekly_outreach.apply(cluster_names,axis=1))\n",
        "df_outreach_cluster.head(3)"
      ],
      "metadata": {
        "id": "SzMqpLmO_afQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying BDR Column"
      ],
      "metadata": {
        "id": "-vP-uoiRAoOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_mx_dict_bdr = dict(zip(df_industries['Industry'],df_industries['MX BDR']))\n",
        "c_br_dict_bdr = dict(zip(df_industries['Industry'],df_industries['BRASIL BDR']))\n",
        "c_latam_dict_bdr = dict(zip(df_industries['Industry'],df_industries['LATAM BDR']))\n",
        "\n",
        "def bdrs_names(df_outreach_cluster):\n",
        "  if(df_outreach_cluster['Country'] == 'Brasil' or df_outreach_cluster['Country'] == 'Brazil'):\n",
        "    return df_outreach_cluster[['Industry']].map(c_br_dict_bdr)\n",
        "  elif (df_outreach_cluster['Country'] == 'Mexico' or df_outreach_cluster['Country'] == 'México'):\n",
        "    return df_outreach_cluster[['Industry']].map(c_mx_dict_bdr)\n",
        "  elif (df_outreach_cluster['Country'] not in ['Brasil','Brazil','Mexico','México']):\n",
        "    return df_outreach_cluster[['Industry']].map(c_latam_dict_bdr)\n",
        "\n",
        "df_outreach = df_outreach_cluster.assign(BDR=df_outreach_cluster.apply(bdrs_names,axis=1))\n",
        "df_outreach.tail(3)"
      ],
      "metadata": {
        "id": "8g56Be3qAECJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SOV7Lewk9Lv"
      },
      "source": [
        "### Transforming & Selecting Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WDvhVnhxIM6"
      },
      "source": [
        "Transforming the dataset columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og-F26MXsjmi"
      },
      "source": [
        "Outreach Table must have the following columns in order:\n",
        "\n",
        "\n",
        "```\n",
        "BDR\tCompany Name\tOwner\tCountry\tCourse 1\tCourse 2\tIndustry\tSector  Pagina Web Full Name\tFirst Name\tScore\tTitle\t\n",
        "Email\tLinkedin\tTelephone\tNeverbounce\tHead Industry\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kliKOm0w0LZ6"
      },
      "outputs": [],
      "source": [
        "df_outreach.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM8tYpamc2Zn"
      },
      "outputs": [],
      "source": [
        "df_outreach.fillna('NA', inplace=True)\n",
        "df_outreach['Date'] = df_outreach['Date'].astype(str)\n",
        "df_outreach['First Name'] = df_outreach['Name'].str.split().str[0]\n",
        "df_outreach.rename(columns={'LGA':'Owner','LinkedIn Profile':'LinkedIn','Industry_T':'Industria'},inplace=True)\n",
        "outreach_output_df = df_outreach[['Cluster','BDR','Company Name','Owner','Country','Course 1','Course 2','Industry','Sector','Head Industry','website','Name','First Name','Score','Title','Email','LinkedIn','Phone','NeverBounce','LastProspDate','LastProspEmailDate','LastHubSpotDate','LastMailShakeDate']]\n",
        "outreach_output_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Aditional Metrics Sheet"
      ],
      "metadata": {
        "id": "sel1STGnYXt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_leads_lga = outreach_output_df[['Owner','Company Name']].groupby('Owner').nunique()\n",
        "w_contacts_lga = outreach_output_df[['Owner','Email']].groupby('Owner').nunique()\n",
        "w_leads_cluster = outreach_output_df[['Cluster','Company Name']].groupby('Cluster').nunique()\n",
        "w_leads_lga['LGA'] = w_leads_lga.index\n",
        "w_contacts_lga['LGA']= w_contacts_lga.index\n",
        "w_leads_cluster['Cluster']= w_leads_cluster.index"
      ],
      "metadata": {
        "id": "09VaGBviYfjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja4nD3xFupiS"
      },
      "source": [
        "## Creating Outreach List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_roLpOvWPaf"
      },
      "outputs": [],
      "source": [
        "ClusterList = outreach_output_df['Cluster'].drop_duplicates().tolist()\n",
        "ClusterList"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating FIle and adding metrics sheet"
      ],
      "metadata": {
        "id": "j0cfqbT5Znwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "today2 = date.today()\n",
        "offset2 = (today2.weekday() -1) % 7\n",
        "last_tuesday2 = today2 - timedelta(days=offset2)\n",
        "out_tuesday = last_tuesday2.strftime(\"%m-%d-%y\")\n",
        "out_tuesday"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-5mJqKMgaNBL",
        "outputId": "a7c1e097-4b23-4b43-96e5-f85f4d33cc40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'01-18-22'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8kPMnhVi5CP"
      },
      "outputs": [],
      "source": [
        "ss_create = gc.create(\"Outreach List \"+ out_tuesday,\"KEY\")\n",
        "ss_1 = ss_create.sheet1\n",
        "aoa1 = [w_leads_lga.columns.tolist()] + w_leads_lga.to_numpy().tolist()\n",
        "aoa2 = [w_contacts_lga.columns.tolist()] + w_contacts_lga.to_numpy().tolist()\n",
        "aoa3 = [w_leads_cluster.columns.tolist()] + w_leads_cluster.to_numpy().tolist()\n",
        "ss_1.update(\"A1\",aoa1)\n",
        "ss_1.update(\"D1\",aoa2)\n",
        "ss_1.update(\"F1\",aoa3)\n",
        "ss_1.update_title(\"General Info\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klQE-Htldft5"
      },
      "source": [
        "Funtion that uses Cluster matching from Flag column to create sheets with separate ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqP_fig7XXVP"
      },
      "outputs": [],
      "source": [
        "outreach_output_df.fillna('', inplace=True) # preventing API error\n",
        "def createSpreadsheet(Cluster):\n",
        "  ndf = outreach_output_df[outreach_output_df['Cluster'] == Cluster]\n",
        "  nlist = [ndf.columns.tolist()] + ndf.to_numpy().tolist()\n",
        "  nws = ss_create.add_worksheet(title=Cluster,rows=150,cols=30)\n",
        "  nws.update_title(Cluster)\n",
        "  nws.update(\"A1\",nlist)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update command using the function"
      ],
      "metadata": {
        "id": "swf8_YWbX4Cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6NLAl_lY5XC"
      },
      "outputs": [],
      "source": [
        "for Cluster in ClusterList:\n",
        "  createSpreadsheet(Cluster)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is a table with a 'General Info' sheet with calculations like Leads by Saleperson, Contacts by Salespersion and Leads by Cluster (focused sales operation). \n",
        "\n",
        "Along separate sheets by Sales Specialized Cluster with cleaned and processed data from clients for Business Development Representatives to use in Email Marketing and Outreach sales strategies."
      ],
      "metadata": {
        "id": "39uvg2yYX8i4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7rSmljVbEYWy",
        "OwoAofp_FKEH"
      ],
      "name": "Outreach_Lead_Lists_ETL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}